import numpy as np
from collections import defaultdict
from models.quantile_regression_tree import QuantileRegressionTree

class QuantileRegressionForest:
    """
    Quantile Regression Forest wrapperï¼Œ
    åˆ©ç”¨å·²å­˜åœ¨çš„ QuantileRegressionTreeï¼Œ
    é€éå°‡åŒä¸€è¨“ç·´é›†ä¸Ÿçµ¦æ¯æ£µæ¨¹ï¼Œä¸¦è¨˜éŒ„æ¯æ£µæ¨¹æ¯å€‹è‘‰ç¯€é»å°æ‡‰çš„ y åˆ†å¸ƒï¼Œ
    ä¾†åš conditional quantile estimateã€‚
    """
    def __init__(self,
                 n_estimators=100,
                 quantile=0.5,
                 max_depth=5,
                 min_samples_leaf=1,
                 bootstrap=True,
                 random_state=None):
        self.n_estimators = n_estimators
        self.quantile    = quantile
        self.max_depth   = max_depth
        self.min_samples_leaf    = min_samples_leaf
        self.bootstrap   = bootstrap
        self.random_state= random_state

        self.trees       = []   # å­˜æ”¾ QuantileRegressionTree instance
        self.leaf_values = []   # å°æ‡‰æ¯æ£µæ¨¹ï¼šleaf_id -> [y1, y2, â€¦] æ˜ å°„

    def _apply_tree(self, tree, X):
        """
        æ ¹æ“š tree.tree_nodes å’Œ tree.children_mapï¼Œ
        æ¨¡ä»¿ apply()ï¼šæŠŠæ¯ç­† X å°æ‡‰åˆ°è‘‰ç¯€é»çš„ node_idã€‚
        """
        node_ids = []
        for x in X:
            node_id = 0
            # èµ°åˆ°è‘‰ç¯€ç¯€é»ç‚ºæ­¢
            while node_id in tree.children_map:
                found_child = False
                for child in tree.children_map[node_id]:
                    feat = child['feature_name']
                    try:
                        idx = tree.feature_names.index(feat)
                    except ValueError:
                        # å¦‚æœç‰¹å¾µåç¨±ä¸å­˜åœ¨ï¼Œè·³éé€™å€‹å­ç¯€é»
                        continue
                    
                    try:
                        val = float(x[idx])
                    except (ValueError, IndexError):
                        # å¦‚æœç„¡æ³•è½‰æ›æˆ–ç´¢å¼•è¶…å‡ºç¯„åœï¼Œè·³é
                        continue
                    
                    if child['condition'] == '<' and val < child['numeric_threshold']:
                        node_id = child['node_id']
                        found_child = True
                        break
                    elif child['condition'] == '>=' and val >= child['numeric_threshold']:
                        node_id = child['node_id']
                        found_child = True
                        break
                
                if not found_child:
                    # å¦‚æœæ¢ä»¶éƒ½ä¸ç¬¦åˆæˆ–ç™¼ç”ŸéŒ¯èª¤ï¼Œé¸æ“‡ç¬¬ä¸€å€‹æœ‰æ•ˆçš„å­ç¯€é»
                    if tree.children_map[node_id]:
                        node_id = tree.children_map[node_id][0]['node_id']
                    else:
                        # å¦‚æœæ²’æœ‰å­ç¯€é»ï¼Œåœæ­¢éæ­·
                        break
            node_ids.append(node_id)
        return node_ids

    def fit(self, X, y):
        """
        1. å»º n_estimators æ£µ QuantileRegressionTreeï¼ˆç”¨ paper å»ºè­°çš„åˆ‡åˆ†ï¼‰
        2. å»ºç«‹æ¯æ£µæ¨¹çš„ leaf_id -> [y å€¼æ¸…å–®] æ˜ å°„
        """
        self.trees = []
        self.leaf_values = []
        rng = np.random.default_rng(self.random_state)
        
        if hasattr(X, 'shape'):
            n = X.shape[0]
        else:
            n = len(X)
            
        if hasattr(X, 'columns'):
            # pandas DataFrame
            feature_names = list(X.columns)
            X = X.values  
        else:
            X = np.array(X)
            feature_names = [f"feature_{i}" for i in range(X.shape[1])]
        
        y = np.array(y)  
        
        self._fallback_quantile = np.quantile(y, self.quantile)

        # ğŸŒ² å»ºç«‹ n_estimators æ£µé‡åŒ–å›æ­¸æ¨¹
        for i in range(self.n_estimators):
            # ğŸ² Bootstrap æŠ½æ¨£ï¼šå¾åŸå§‹è³‡æ–™ä¸­æœ‰æ”¾å›åœ°æŠ½å–æ¨£æœ¬
            # æ¯æ£µæ¨¹ä½¿ç”¨ä¸åŒçš„è³‡æ–™å­é›†ä»¥å¢åŠ å¤šæ¨£æ€§
            idx = rng.choice(n, size=n, replace=self.bootstrap)
            Xs, ys = X[idx], y[idx]  # ç¬¬ i æ£µæ¨¹çš„è¨“ç·´è³‡æ–™

            # ğŸŒ± å»ºç«‹ç¬¬ i æ£µé‡åŒ–å›æ­¸æ¨¹
            tree = QuantileRegressionTree(
                split_criterion='r2',    # ä½¿ç”¨ RÂ² è©•ä¼°åˆ†å‰²å“è³ª
                max_depth=self.max_depth,  # æ¨¹çš„æœ€å¤§æ·±åº¦é™åˆ¶
                min_samples_leaf=self.min_samples_leaf,    # è‘‰ç¯€é»æœ€å°æ¨£æœ¬æ•¸
                # ç¢ºä¿æ¯æ£µæ¨¹æœ‰ä¸åŒçš„éš¨æ©Ÿç¨®å­ä»¥å¢åŠ å¤šæ¨£æ€§
                random_state=(None if self.random_state is None else self.random_state + i)
            )
            # è¨“ç·´æ¨¹ï¼Œquantile åƒæ•¸ç”¨æ–¼åˆ†å‰²æº–å‰‡è¨ˆç®—
            tree.fit(Xs, ys, quantile=self.quantile, feature_names=feature_names)
            self.trees.append(tree)  # å°‡è¨“ç·´å¥½çš„æ¨¹åŠ å…¥æ£®æ—

            # ğŸ“Š å»ºç«‹è‘‰ç¯€é» ID åˆ° y å€¼çš„æ˜ å°„
            # é€™æ˜¯ QRF çš„æ ¸å¿ƒï¼šè¨˜éŒ„æ¯å€‹è‘‰ç¯€é»åŒ…å«çš„ y å€¼åˆ†å¸ƒ
            leaf_ids = self._apply_tree(tree, Xs)  # ç²å–æ¯å€‹è¨“ç·´æ¨£æœ¬å°æ‡‰çš„è‘‰ç¯€é» ID
            mapping = defaultdict(list)  # å»ºç«‹æ˜ å°„ï¼šleaf_id -> [y å€¼åˆ—è¡¨]
            
            # å°‡æ¯å€‹ y å€¼åˆ†é…åˆ°å°æ‡‰çš„è‘‰ç¯€é»
            for leaf_id, yi in zip(leaf_ids, ys):
                mapping[leaf_id].append(yi)  # è¨˜éŒ„è©²è‘‰ç¯€é»åŒ…å«çš„ y å€¼
            
            # å„²å­˜ç¬¬ i æ£µæ¨¹çš„è‘‰ç¯€é»æ˜ å°„ï¼Œä¾›é æ¸¬æ™‚ä½¿ç”¨
            self.leaf_values.append(mapping)

        return self

    def predict_quantile(self, X, alpha):
        """
        é æ¸¬æŒ‡å®šåˆ†ä½æ•¸ alpha çš„å€¼
        
        æ ¸å¿ƒæ¼”ç®—æ³•ï¼š
        1. å°æ¯å€‹æ¸¬è©¦æ¨£æœ¬ï¼Œå°‡å…¶é€šéæ‰€æœ‰æ¨¹æ‰¾åˆ°å°æ‡‰çš„è‘‰ç¯€é»
        2. å¾æ¯å€‹è‘‰ç¯€é»æ”¶é›†è¨“ç·´æ™‚çš„ y å€¼
        3. èšåˆæ‰€æœ‰ y å€¼å¾Œè¨ˆç®— alpha åˆ†ä½æ•¸
        
        Parameters
        ----------
        X : array-like, shape (n_samples, n_features)
            æ¸¬è©¦æ¨£æœ¬ç‰¹å¾µ
        alpha : float, range (0, 1)
            ç›®æ¨™åˆ†ä½æ•¸ï¼Œä¾‹å¦‚ 0.5 è¡¨ç¤ºä¸­ä½æ•¸
            
        Returns
        -------
        predictions : ndarray, shape (n_samples,)
            æ¯å€‹æ¨£æœ¬çš„ alpha åˆ†ä½æ•¸é æ¸¬å€¼
        """
        # ğŸ”„ çµ±ä¸€è¼¸å…¥æ ¼å¼ï¼šç¢ºä¿ X æ˜¯ numpy array
        if hasattr(X, 'values'):
            # pandas DataFrame â†’ numpy array
            X_arr = X.values
        else:
            X_arr = np.array(X)
            
        preds = []  # å„²å­˜æ¯å€‹æ¨£æœ¬çš„é æ¸¬çµæœ
        
        # ğŸ¯ å°æ¯å€‹æ¸¬è©¦æ¨£æœ¬é€²è¡Œé æ¸¬
        for x in X_arr:
            agg = []  # èšåˆä¾†è‡ªæ‰€æœ‰æ¨¹çš„ y å€¼
            
            # ğŸŒ³ éæ­·æ£®æ—ä¸­çš„æ¯æ£µæ¨¹
            for tree, mapping in zip(self.trees, self.leaf_values):
                try:
                    # æ‰¾åˆ°è©²æ¨£æœ¬åœ¨æ­¤æ¨¹ä¸­å°æ‡‰çš„è‘‰ç¯€é» ID
                    leaf_id = self._apply_tree(tree, [x])[0]
                    
                    # å¾é å…ˆè¨ˆç®—çš„æ˜ å°„ä¸­å–å¾—è©²è‘‰ç¯€é»çš„ y å€¼åˆ—è¡¨
                    leaf_values = mapping.get(leaf_id, [])
                    
                    # å°‡é€™äº› y å€¼åŠ å…¥èšåˆåˆ—è¡¨
                    agg.extend(leaf_values)
                except (IndexError, KeyError, ValueError):
                    # å¦‚æœæŸæ£µæ¨¹è™•ç†å¤±æ•—ï¼ˆä¾‹å¦‚è³‡æ–™æ ¼å¼å•é¡Œï¼‰ï¼Œè·³éè©²æ¨¹
                    # é€™æä¾›äº†å®¹éŒ¯æ©Ÿåˆ¶ï¼Œå³ä½¿éƒ¨åˆ†æ¨¹å¤±æ•ˆä¹Ÿèƒ½ç¹¼çºŒé æ¸¬
                    continue
            
            # ğŸ“Š è¨ˆç®—èšåˆå¾Œçš„åˆ†ä½æ•¸
            if len(agg) > 0:
                # æœ‰è¶³å¤ è³‡æ–™æ™‚ï¼Œè¨ˆç®— alpha åˆ†ä½æ•¸
                preds.append(np.quantile(agg, alpha))
            else:
                # ğŸš¨ å®¹éŒ¯æ©Ÿåˆ¶ï¼šå¦‚æœæ²’æœ‰æœ‰æ•ˆè³‡æ–™ï¼Œä½¿ç”¨å‚™ç”¨å€¼
                if hasattr(self, '_fallback_quantile'):
                    # ä½¿ç”¨è¨“ç·´æ™‚è¨ˆç®—çš„å‚™ç”¨åˆ†ä½æ•¸
                    preds.append(self._fallback_quantile)
                else:
                    # æœ€å¾Œçš„å‚™ç”¨æ–¹æ¡ˆ
                    preds.append(0.0)
                    
        return np.array(preds)  # è¿”å› numpy array æ ¼å¼çš„é æ¸¬çµæœ

    def predict(self, X):
        """
        ä¾¿åˆ©æ–¹æ³•ï¼šä½¿ç”¨åˆå§‹åŒ–æ™‚è¨­å®šçš„é è¨­åˆ†ä½æ•¸é€²è¡Œé æ¸¬
        
        Parameters
        ----------
        X : array-like, shape (n_samples, n_features)
            æ¸¬è©¦æ¨£æœ¬ç‰¹å¾µ
            
        Returns
        -------
        predictions : ndarray, shape (n_samples,)
            ä½¿ç”¨é è¨­åˆ†ä½æ•¸çš„é æ¸¬å€¼
        """
        return self.predict_quantile(X, self.quantile)

    def predict_interval(self, X, lower_q, upper_q):
        """
        ä¾¿åˆ©æ–¹æ³•ï¼šé æ¸¬æŒ‡å®šçš„é æ¸¬å€é–“
        
        Parameters
        ----------
        X : array-like, shape (n_samples, n_features)
            æ¸¬è©¦æ¨£æœ¬ç‰¹å¾µ
        lower_q : float, range (0, 1)
            å€é–“ä¸‹ç•Œåˆ†ä½æ•¸ï¼Œä¾‹å¦‚ 0.05 è¡¨ç¤º 5% åˆ†ä½æ•¸
        upper_q : float, range (0, 1)
            å€é–“ä¸Šç•Œåˆ†ä½æ•¸ï¼Œä¾‹å¦‚ 0.95 è¡¨ç¤º 95% åˆ†ä½æ•¸
            
        Returns
        -------
        lower : ndarray, shape (n_samples,)
            é æ¸¬å€é–“çš„ä¸‹ç•Œå€¼
        upper : ndarray, shape (n_samples,)
            é æ¸¬å€é–“çš„ä¸Šç•Œå€¼
            
        Examples
        --------
        >>> # é æ¸¬ 90% é æ¸¬å€é–“ (5%-95%)
        >>> lower, upper = qrf.predict_interval(X_test, 0.05, 0.95)
        >>> # é æ¸¬ 50% é æ¸¬å€é–“ (25%-75%)
        >>> lower, upper = qrf.predict_interval(X_test, 0.25, 0.75)
        """
        lower = self.predict_quantile(X, lower_q)  # è¨ˆç®—ä¸‹ç•Œ
        upper = self.predict_quantile(X, upper_q)  # è¨ˆç®—ä¸Šç•Œ
        return lower, upper
