{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86645ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "esg_words = ['clean', 'environmental', 'epa', 'sustainability', 'climate', 'warming', 'biofuel', 'biofuels', 'green', 'renewable', 'solar', 'stewardship', 'wind', 'atmosphere', 'emission', 'emissions', 'emit', 'ghg', 'ghgs', 'greenhouse', 'agriculture', 'deforestation', 'pesticide', 'pesticides', 'wetlands', 'zoning', 'biodiversity', 'species', 'wilderness', 'wildlife', 'freshwater', 'groundwater', 'water', 'cleaner', 'cleanup', 'coal', 'contamination', 'fossil', 'resource', 'air', 'carbon', 'nitrogen', 'pollution', 'superfund', 'biphenyls', 'hazardous', 'householding', 'pollutants', 'printing', 'recycle', 'recycling', 'toxic', 'waste', 'wastes', 'weee', 'climate change', 'conservation', 'environmentally', 'footprint', 'global warming', 'pollutant', 'recycled', 'sustainable', 'sustainably',\n",
    "'citizen', 'citizens', 'csr', 'disabilities', 'disability', 'disabled', 'human', 'nations', 'social', 'un', 'veteran', 'veterans', 'vulnerable', 'dignity', 'discriminate', 'discriminated', 'discriminating', 'discrimination', 'equality', 'freedom', 'humanity', 'nondiscrimination', 'sexual', 'communities', 'community', 'expression', 'marriage', 'privacy', 'peace', 'bargaining', 'eeo', 'fairness', 'fla', 'harassment', 'injury', 'labor', 'overtime', 'ruggie', 'sick', 'wage', 'wages', 'workplace', 'bisexual', 'diversity', 'ethnic', 'ethnically', 'ethnicities', 'ethnicity', 'female', 'females', 'gay', 'gays', 'gender', 'genders', 'homosexual', 'immigration', 'lesbian', 'lesbians', 'lgbt', 'minorities', 'minority', 'ms', 'race', 'racial', 'religion', 'religious', 'sex', 'transgender', 'woman',\n",
    "'women', 'occupational', 'safe', 'safely', 'safety', 'ilo', 'labour', 'eicc', 'children', 'epidemic', 'health', 'healthy', 'ill', 'illness', 'pandemic', 'childbirth', 'drug', 'medicaid', 'medicare', 'medicine', 'medicines', 'hiv', 'alcohol', 'drinking', 'bugs', 'conformance', 'defects', 'fda', 'inspection', 'inspections', 'minerals', 'standardization', 'warranty', 'endowment', 'endowments', 'people', 'philanthropic', 'philanthropy', 'socially', 'societal', 'society', 'welfare', 'charitable', 'charities', 'charity', 'donate', 'donated', 'donates', 'donating', 'donation', 'donations', 'donors', 'foundation', 'foundations', 'gift', 'gifts', 'nonprofit', 'poverty', 'courses', 'educate', 'educated', 'educates', 'educating', 'education', 'educational', 'learning', 'mentoring', 'scholarships', 'teach', 'teacher', 'teachers', 'teaching', 'training', 'employ', 'employment', 'headcount', 'hire', 'hired', 'hires', 'hiring', 'staffing', 'unemployment',\n",
    "'align', 'aligned', 'aligning', 'alignment', 'aligns', 'bylaw', 'bylaws', 'charter', 'charters', 'culture', 'death', 'duly', 'independent', 'parents', 'cobc', 'ethic', 'ethical', 'ethically', 'ethics', 'honesty', 'bribery', 'corrupt', 'corruption', 'crimes', 'embezzlement', 'grassroots', 'influence', 'influences', 'influencing', 'lobbied', 'lobbies', 'lobby', 'lobbying', 'lobbyist', 'lobbyists', 'whistleblower', 'compliance', 'conduct', 'conformity', 'governance', 'misconduct', 'parachute', 'parachutes', 'perquisites', 'plane', 'planes', 'poison', 'retirement', 'approval', 'approvals', 'approve', 'approved', 'approves', 'approving', 'assess', 'assessed', 'assesses', 'assessing', 'assessment', 'assessments', 'audit', 'audited', 'auditing', 'auditor', 'auditors', 'audits', 'control', 'controls', 'coso', 'detect', 'detected', 'detecting', 'detection', 'evaluate', 'evaluated', 'evaluates', 'evaluating', 'evaluation', 'evaluations', 'examination',\n",
    "'examinations', 'examine', 'examined', 'examines', 'examining', 'irs', 'oversee', 'overseeing', 'oversees', 'oversight', 'review', 'reviewed', 'reviewing', 'reviews', 'rotation', 'test', 'tested', 'testing', 'tests', 'treadway', 'backgrounds', 'independence', 'leadership', 'nomination', 'nominations', 'nominee', 'nominees', 'perspectives', 'qualifications', 'refreshment', 'skill', 'skills', 'succession', 'tenure', 'vacancies', 'vacancy', 'appreciation', 'award', 'awarded', 'awarding', 'awards', 'bonus', 'bonuses', 'cd', 'compensate', 'compensated', 'compensates', 'compensating', 'compensation', 'eip', 'iso', 'isos', 'payout', 'payouts', 'pension', 'prsu', 'prsus', 'recoupment', 'remuneration', 'reward', 'rewarding', 'rewards', 'rsu', 'rsus', 'salaries', 'salary', 'severance', 'vest', 'vested', 'vesting', 'vests', 'ballot', 'ballots', 'cast', 'consent', 'elect', 'elected', 'electing', 'election', 'elections', 'elects', 'nominate', 'nominated',\n",
    "'plurality', 'proponent', 'proponents', 'proposal', 'proposals', 'proxies', 'quorum', 'vote', 'voted', 'votes', 'voting', 'attract', 'attracting', 'attracts', 'incentive', 'incentives', 'interview', 'interviews', 'motivate', 'motivated', 'motivates', 'motivating', 'motivation', 'recruit', 'recruiting', 'recruitment', 'retain', 'retainer', 'retainers', 'retaining', 'retention', 'talent', 'talented', 'talents', 'brother', 'clicking', 'conflict', 'conflicts', 'family', 'grandchildren', 'grandparent', 'grandparents', 'inform', 'insider', 'insiders', 'inspector', 'inspectors', 'interlocks', 'nephews', 'nieces', 'posting', 'relatives', 'siblings', 'sister', 'son', 'spousal', 'spouse', 'spouses', 'stepchildren', 'stepparents', 'transparency', 'transparent', 'visit', 'visiting', 'visits', 'webpage', 'website', 'announce', 'announced', 'announcement', 'announcements', 'announces', 'announcing', 'communicate', 'communicated', 'communicates', 'communicating',\n",
    "'erm', 'fairly', 'integrity', 'liaison', 'presentation', 'presentations', 'asc', 'disclose', 'disclosed', 'discloses', 'disclosing', 'disclosure', 'disclosures', 'fasb', 'gaap', 'objectivity', 'press', 'sarbanes', 'engagement', 'engagements', 'feedback', 'hotline', 'investor', 'invite', 'invited', 'mail', 'mailed', 'mailing', 'mailings', 'notice', 'relations', 'stakeholder', 'stakeholders', 'compact', 'ungc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "111fbc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/coconut/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/coconut/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "366f1d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/coconut/Google Drive/我的雲端硬碟/esg財報資料\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba8e30e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "df = dd.read_csv(f\"{path}/AR_data_r_v3.csv\", encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "752b691f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CIK', 'Company', 'Type', 'Filing Date', 'filename', 'cleaned_data',\n",
       "       'ticker', 'BIDLO_-4d', 'ASKHI_-4d', 'PRC_-4d', 'OPENPRC_-4d',\n",
       "       'BIDLO_-3d', 'ASKHI_-3d', 'PRC_-3d', 'OPENPRC_-3d', 'BIDLO_-2d',\n",
       "       'ASKHI_-2d', 'PRC_-2d', 'OPENPRC_-2d', 'BIDLO_-1d', 'ASKHI_-1d',\n",
       "       'PRC_-1d', 'OPENPRC_-1d', 'BIDLO_0d', 'ASKHI_0d', 'PRC_0d',\n",
       "       'OPENPRC_0d', 'BIDLO_1d', 'ASKHI_1d', 'PRC_1d', 'OPENPRC_1d',\n",
       "       'BIDLO_2d', 'ASKHI_2d', 'PRC_2d', 'OPENPRC_2d', 'BIDLO_3d', 'ASKHI_3d',\n",
       "       'PRC_3d', 'OPENPRC_3d', 'BIDLO_4d', 'ASKHI_4d', 'PRC_4d', 'OPENPRC_4d',\n",
       "       'BL', 'BH', 'AL', 'AH', 'direction', 'range', 'category',\n",
       "       'filtered_text', 'Year', 'predicted_category', 'trade_type',\n",
       "       'trade_action', 'sell_day_offset', 'exit_date', 'ERRet', '4d_ExRet',\n",
       "       'ret_firm_t0', 'ret_firm_t1', 'ret_firm_t2', 'ret_firm_t3',\n",
       "       'ret_firm_t4', 'market_date_t-1', 'market_date_t0', 'market_date_t1',\n",
       "       'market_date_t2', 'market_date_t3', 'market_date_t4', 'ret_mkt_t0',\n",
       "       'ret_mkt_t1', 'ret_mkt_t2', 'ret_mkt_t3', 'ret_mkt_t4', 'cum_firm_ret',\n",
       "       'cum_mkt_ret', 'Δr_i'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e878f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>range</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.203684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.071175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.071188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.174856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             range\n",
       "category          \n",
       "1         0.203684\n",
       "2         0.071175\n",
       "3        -0.000787\n",
       "4        -0.071188\n",
       "5        -0.174856"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['range', 'category']].head(1000).groupby('category').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d281c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted_category</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.729373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.497041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.851852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.808824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.657658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    category\n",
       "predicted_category          \n",
       "1                   2.729373\n",
       "2                   2.497041\n",
       "3                   2.851852\n",
       "4                   2.808824\n",
       "5                   2.657658"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['predicted_category', 'category']].head(3000).groupby('predicted_category').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "734826f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    positive\n",
       "1    negative\n",
       "3    positive\n",
       "4    positive\n",
       "5    negative\n",
       "Name: direction, dtype: string"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['direction'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23905b02",
   "metadata": {},
   "source": [
    "### Data description\n",
    "\n",
    "| 欄位名稱 | 說明 |\n",
    "|-----------|------|\n",
    "| **CIK** | SEC 中每間公司的唯一識別碼（Central Index Key）。 |\n",
    "| **Company** | 公司名稱。 |\n",
    "| **Type** | 檔案類型（例如 10-K、10-Q、8-K）。 |\n",
    "| **Filing Date** | 提交給 SEC 的日期。 |\n",
    "| **filename** | 該財報或公告文件的檔案名稱。 |\n",
    "| **cleaned_data** | 清理過後的文字內容（去掉 HTML 標籤、特殊字元等）。 |\n",
    "| **ticker** | 股票代號。 |\n",
    "| **BIDLO** | 當日最低買價（Bid Low）。 |\n",
    "| **ASKHI** | 當日最高賣價（Ask High）。 |\n",
    "| **PRC** | 收盤價（Price）。 |\n",
    "| **OPENPRC** | 開盤價（Open Price）。 |\n",
    "| **BL**, **BH** | 「事件前低價」、「事件後高價」 |\n",
    "| **AL**, **AH** | 「公告前低價」、「公告後高價」|\n",
    "| **direction** | 股價走勢 |\n",
    "| **range** | 價格波動 有分上漲跟下跌 |\n",
    "| **category** | 根據漲幅做的分類 |\n",
    "| **filtered_text** | 篩選後的文字（可能是情緒分析前的結果）。 |\n",
    "| **Year** | 財報年份。 |\n",
    "| **predicted_category** | NLP 模型預測的情緒或財報分類。 |\n",
    "| **trade_type** | 交易類型（例如 “long” / “short”）。 |\n",
    "| **trade_action** | 實際執行動作（Buy/Sell）。 |\n",
    "| **sell_day_offset** | 出場日相對於事件日的天數（例如 +2 表示第2天賣出）。 |\n",
    "| **exit_date** | 實際出場日期。 |\n",
    "| **ERRet** | 事件日的超額報酬（Event-day Excess Return）。 |\n",
    "| **4d_ExRet** | 事件後四天累積超額報酬（Cumulative Excess Return over +4d）。 |\n",
    "| **ret_firm_t0 ~ ret_firm_t4** | 公司在事件日到 +4 日的日報酬率。 |\n",
    "| **ret_mkt_t0 ~ ret_mkt_t4** | 市場（例如 S&P 500 或 NASDAQ）在相同期間的報酬率。 |\n",
    "| **market_date_t-1 ~ market_date_t4** | 市場報酬計算對應的交易日。 |\n",
    "| **cum_firm_ret** | 公司在整個事件視窗的累積報酬。 |\n",
    "| **cum_mkt_ret** | 市場在整個事件視窗的累積報酬。 |\n",
    "| **Δr_i** | 公司相對市場的超額報酬（Δr_i = cum_firm_ret − cum_mkt_ret）。 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "65c25fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/coconut/qrt/.venv/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "import dask.dataframe as dd\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "df = dd.read_csv(f\"{path}/AR_data_r_v3.csv\", encoding='utf-8-sig')\n",
    "\n",
    "df = df[\n",
    "    df[\"category\"].isin([1, 2, 3, 4, 5]) &\n",
    "    (~df[\"trade_type\"].isin([\"no_trade\"]))\n",
    "].copy()\n",
    "\n",
    "\n",
    "def tokenize_and_stem(text: str) -> list[str]:\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = nltk.word_tokenize(str(text).lower())\n",
    "    return [stemmer.stem(tok) for tok in tokens if tok.isalpha()]\n",
    "\n",
    "\n",
    "texts = df['filtered_text'].fillna('').apply(str, meta=('filtered_text', 'object')).compute()\n",
    "vectorizer = CountVectorizer(\n",
    "    tokenizer=tokenize_and_stem,\n",
    "    vocabulary=esg_words,\n",
    "    lowercase=True\n",
    ")\n",
    "tf_matrix  = vectorizer.fit_transform(texts)\n",
    "\n",
    "N    = tf_matrix.shape[0]\n",
    "df_j = (tf_matrix > 0).sum(axis=0).A1\n",
    "\n",
    "idf = np.log((N + 1) / (df_j + 1)) + 1\n",
    "\n",
    "tfidf_matrix = tf_matrix.multiply(idf)\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "tfidf_df = pd.DataFrame(\n",
    "    tfidf_matrix.toarray(),\n",
    "    columns=[f\"{w}_TFIDF\" for w in feature_names]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "83ea5fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df[\"category\"] = df['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aa8e9602",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df[\"direction\"] = df['direction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4ad9c406",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df = tfidf_df.loc[:, (tfidf_df != 0).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "06b51c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_TFIDF</th>\n",
       "      <th>epa_TFIDF</th>\n",
       "      <th>biofuel_TFIDF</th>\n",
       "      <th>green_TFIDF</th>\n",
       "      <th>solar_TFIDF</th>\n",
       "      <th>stewardship_TFIDF</th>\n",
       "      <th>wind_TFIDF</th>\n",
       "      <th>emit_TFIDF</th>\n",
       "      <th>ghg_TFIDF</th>\n",
       "      <th>water_TFIDF</th>\n",
       "      <th>...</th>\n",
       "      <th>asc_TFIDF</th>\n",
       "      <th>fasb_TFIDF</th>\n",
       "      <th>gaap_TFIDF</th>\n",
       "      <th>press_TFIDF</th>\n",
       "      <th>feedback_TFIDF</th>\n",
       "      <th>investor_TFIDF</th>\n",
       "      <th>mail_TFIDF</th>\n",
       "      <th>compact_TFIDF</th>\n",
       "      <th>category</th>\n",
       "      <th>direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.945691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.048166</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.291093</td>\n",
       "      <td>3.968134</td>\n",
       "      <td>3.108565</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.654598</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.659135</td>\n",
       "      <td>7.685026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.5265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.654598</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.079219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97439</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.654598</td>\n",
       "      <td>23.808804</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.572249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97440</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.731526</td>\n",
       "      <td>3.981897</td>\n",
       "      <td>1.322711</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.572249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97441</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.453709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.026844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.654598</td>\n",
       "      <td>7.936268</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.620415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97442</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.194579</td>\n",
       "      <td>2.654598</td>\n",
       "      <td>22.486093</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.524083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97443</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.389158</td>\n",
       "      <td>1.327299</td>\n",
       "      <td>10.581691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.144498</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97444 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       clean_TFIDF  epa_TFIDF  biofuel_TFIDF  green_TFIDF  solar_TFIDF  \\\n",
       "0         0.000000   0.000000            0.0          0.0     0.000000   \n",
       "1         0.000000   0.000000            0.0          0.0     0.000000   \n",
       "2         0.000000   0.000000            0.0          0.0     0.000000   \n",
       "3         0.000000   0.000000            0.0          0.0     0.000000   \n",
       "4         3.659135   7.685026            0.0          0.0     0.000000   \n",
       "...            ...        ...            ...          ...          ...   \n",
       "97439     0.000000   0.000000            0.0          0.0     0.000000   \n",
       "97440     0.000000   0.000000            0.0          0.0     0.000000   \n",
       "97441     0.000000   0.000000            0.0          0.0     4.453709   \n",
       "97442     0.000000   0.000000            0.0          0.0     0.000000   \n",
       "97443     0.000000   0.000000            0.0          0.0     0.000000   \n",
       "\n",
       "       stewardship_TFIDF  wind_TFIDF  emit_TFIDF  ghg_TFIDF  water_TFIDF  ...  \\\n",
       "0                    0.0    0.000000         0.0        0.0       0.0000  ...   \n",
       "1                    0.0    0.000000         0.0        0.0       0.0000  ...   \n",
       "2                    0.0    0.000000         0.0        0.0       0.0000  ...   \n",
       "3                    0.0    0.000000         0.0        0.0       0.0000  ...   \n",
       "4                    0.0    0.000000         0.0        0.0      11.5265  ...   \n",
       "...                  ...         ...         ...        ...          ...  ...   \n",
       "97439                0.0    0.000000         0.0        0.0       0.0000  ...   \n",
       "97440                0.0    0.000000         0.0        0.0       0.0000  ...   \n",
       "97441                0.0    4.026844         0.0        0.0       0.0000  ...   \n",
       "97442                0.0    0.000000         0.0        0.0       0.0000  ...   \n",
       "97443                0.0    0.000000         0.0        0.0       0.0000  ...   \n",
       "\n",
       "       asc_TFIDF  fasb_TFIDF  gaap_TFIDF  press_TFIDF  feedback_TFIDF  \\\n",
       "0       0.000000    0.000000    0.000000     0.000000             0.0   \n",
       "1       0.000000   11.945691    0.000000     0.000000             0.0   \n",
       "2       0.000000    9.291093    3.968134     3.108565             0.0   \n",
       "3       0.000000    2.654598    0.000000     0.000000             0.0   \n",
       "4       0.000000    2.654598    0.000000     0.000000             0.0   \n",
       "...          ...         ...         ...          ...             ...   \n",
       "97439   0.000000    2.654598   23.808804     0.000000             0.0   \n",
       "97440   1.731526    3.981897    1.322711     0.000000             0.0   \n",
       "97441   0.000000    2.654598    7.936268     0.000000             0.0   \n",
       "97442   5.194579    2.654598   22.486093     0.000000             0.0   \n",
       "97443  10.389158    1.327299   10.581691     0.000000             0.0   \n",
       "\n",
       "       investor_TFIDF  mail_TFIDF  compact_TFIDF  category  direction  \n",
       "0            0.000000    0.000000            0.0         1   positive  \n",
       "1            3.048166    0.000000            0.0         5   negative  \n",
       "2            0.000000    0.000000            0.0         2   positive  \n",
       "3            0.000000    0.000000            0.0         1   positive  \n",
       "4            0.000000    4.079219            0.0         5   negative  \n",
       "...               ...         ...            ...       ...        ...  \n",
       "97439        4.572249    0.000000            0.0         1   positive  \n",
       "97440        4.572249    0.000000            0.0         5   negative  \n",
       "97441        7.620415    0.000000            0.0         2   positive  \n",
       "97442        1.524083    0.000000            0.0         5   negative  \n",
       "97443        9.144498    0.000000            0.0         1   positive  \n",
       "\n",
       "[97444 rows x 129 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672112a7",
   "metadata": {},
   "source": [
    "## Predict category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "eee73c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/coconut/qrt/.venv/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/coconut/qrt/.venv/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:129: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "X = tfidf_df.drop(columns=['category', 'direction'])\n",
    "y = tfidf_df['category']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "encoder = LabelEncoder()\n",
    "y_train_encoded = encoder.fit_transform(y_train.values.reshape(-1, 1))\n",
    "y_test_encoded = encoder.transform(y_test.values.reshape(-1, 1))\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(64, 32, 16), max_iter=500, random_state=42)\n",
    "mlp.fit(X_train, y_train_encoded)\n",
    "\n",
    "y_pred_encoded = mlp.predict(X_test)\n",
    "y_pred = encoder.inverse_transform(y_pred_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c72a9267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.39      0.36      6045\n",
      "           2       0.30      0.31      0.31      3759\n",
      "           4       0.28      0.18      0.22      3902\n",
      "           5       0.37      0.38      0.38      5783\n",
      "\n",
      "    accuracy                           0.33     19489\n",
      "   macro avg       0.32      0.32      0.32     19489\n",
      "weighted avg       0.33      0.33      0.33     19489\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ec4bf0",
   "metadata": {},
   "source": [
    "## Predict direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ee8119cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/coconut/qrt/.venv/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/coconut/qrt/.venv/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:129: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "X = tfidf_df.drop(columns=['category', 'direction'])\n",
    "y = tfidf_df['direction']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "encoder = LabelEncoder()\n",
    "y_train_encoded = encoder.fit_transform(y_train.values.reshape(-1, 1))\n",
    "y_test_encoded = encoder.transform(y_test.values.reshape(-1, 1))\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(64, 32, 16), max_iter=500, random_state=42)\n",
    "mlp.fit(X_train, y_train_encoded)\n",
    "\n",
    "y_pred_encoded = mlp.predict(X_test)\n",
    "y_pred = encoder.inverse_transform(y_pred_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0e05646f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.46      0.48      9685\n",
      "    positive       0.51      0.54      0.52      9804\n",
      "\n",
      "    accuracy                           0.50     19489\n",
      "   macro avg       0.50      0.50      0.50     19489\n",
      "weighted avg       0.50      0.50      0.50     19489\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "91b4d899",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/coconut/qrt/.venv/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/coconut/qrt/.venv/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:129: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "X = tfidf_df.drop(columns=['category', 'direction'])\n",
    "y = tfidf_df['direction']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "encoder = LabelEncoder()\n",
    "y_train_encoded = encoder.fit_transform(y_train.values.reshape(-1, 1))\n",
    "y_test_encoded = encoder.transform(y_test.values.reshape(-1, 1))\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train_encoded)\n",
    "\n",
    "y_pred_encoded = rf.predict(X_test)\n",
    "y_pred = encoder.inverse_transform(y_pred_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6db4e8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.51      0.50      0.51      9685\n",
      "    positive       0.52      0.52      0.52      9804\n",
      "\n",
      "    accuracy                           0.51     19489\n",
      "   macro avg       0.51      0.51      0.51     19489\n",
      "weighted avg       0.51      0.51      0.51     19489\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02017cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "import dask.dataframe as dd\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "df = dd.read_csv(f\"{path}/AR_data_r_v3.csv\", encoding='utf-8-sig')\n",
    "\n",
    "df = df[\n",
    "    df[\"predicted_category\"].isin([1, 2, 3, 4, 5]) &\n",
    "    (~df[\"trade_type\"].isin([\"no_trade\"]))\n",
    "].copy()\n",
    "\n",
    "\n",
    "def tokenize_and_stem(text: str) -> list[str]:\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = nltk.word_tokenize(str(text).lower())\n",
    "    return [stemmer.stem(tok) for tok in tokens if tok.isalpha()]\n",
    "\n",
    "\n",
    "texts = df['filtered_text'].fillna('').apply(str, meta=('filtered_text', 'object')).compute()\n",
    "vectorizer = CountVectorizer(\n",
    "    tokenizer=tokenize_and_stem,\n",
    "    vocabulary=esg_words,\n",
    "    lowercase=True\n",
    ")\n",
    "tf_matrix  = vectorizer.fit_transform(texts)  # shape = (n_docs, n_words)\n",
    "\n",
    "N    = tf_matrix.shape[0]\n",
    "df_j = (tf_matrix > 0).sum(axis=0).A1\n",
    "\n",
    "idf = np.log((N + 1) / (df_j + 1)) + 1\n",
    "\n",
    "tfidf_matrix = tf_matrix.multiply(idf)\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "tfidf_df = pd.DataFrame(\n",
    "    tfidf_matrix.toarray(),\n",
    "    columns=[f\"{w}_TFIDF\" for w in feature_names]\n",
    ")\n",
    "\n",
    "meta_df = df[['CIK','Filing Date','BL','BH','AL','AH','range']].compute().rename(\n",
    "    columns={\n",
    "        'CIK': '文章ID',\n",
    "        'Filing Date': '日期',\n",
    "        'BL':'BL',\n",
    "        'BH':'BH',\n",
    "        'AL':'AL',\n",
    "        'AH':'AH',\n",
    "        'range': '報酬率'\n",
    "    }\n",
    ").reset_index(drop=True)\n",
    "\n",
    "days   = [-4, -3, -2, -1, 1, 2, 3, 4]\n",
    "fields = ['BIDLO', 'ASKHI', 'PRC', 'OPENPRC']  \n",
    "\n",
    "expected_cols = [f'{f}_{d}d' for d in days for f in fields]\n",
    "\n",
    "have_cols = [c for c in expected_cols if c in df.columns]\n",
    "ohlc_8d = df[have_cols].compute().reset_index(drop=True)   # 注意這裡也要 .compute()\n",
    "\n",
    "output_df = pd.concat(\n",
    "    [meta_df.reset_index(drop=True),\n",
    "     ohlc_8d.reset_index(drop=True),\n",
    "     tfidf_df.reset_index(drop=True)],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "output_df.to_csv(\n",
    "    'data/esg_tfidf_with_return.csv',\n",
    "    index=False,\n",
    "    encoding='utf-8-sig'\n",
    ")\n",
    "\n",
    "print(\"已輸出 → esg_tfidf_with_return.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebec311e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_integer_dtype\n",
    "\n",
    "dfv = pd.read_csv(f\"data/esg_tfidf_with_return.csv\", encoding='utf-8-sig')\n",
    "\n",
    "tf_cols = [c for c in dfv.columns if c.endswith('_TFIDF')]\n",
    "print(f\"TF 欄位數量: {len(tf_cols)}\")\n",
    "\n",
    "print(\"任何缺失值？\", dfv[tf_cols].isna().any().any())\n",
    "na_per_col = dfv[tf_cols].isna().sum()\n",
    "print(\"有缺失的欄位(前10):\\n\", na_per_col[na_per_col>0].sort_values(ascending=False).head(10))\n",
    "\n",
    "arr = dfv[tf_cols].to_numpy()\n",
    "print(\"任何正/負無限？\", np.isinf(arr).any())\n",
    "\n",
    "all_int = all(is_integer_dtype(dfv[c]) for c in tf_cols)\n",
    "print(\"所有 TF 欄都是整數型別？\", all_int)\n",
    "\n",
    "for c in tf_cols:\n",
    "    if not is_integer_dtype(dfv[c]):\n",
    "        dfv[c] = dfv[c].fillna(0).round().astype(int)\n",
    "dfv.to_csv(\n",
    "    'data/esg_tfidf_with_return_cleaned.csv',\n",
    "    index=False,\n",
    "    encoding='utf-8-sig'\n",
    ") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qrt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
